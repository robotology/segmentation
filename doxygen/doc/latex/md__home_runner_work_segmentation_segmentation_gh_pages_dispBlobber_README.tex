Module to detect the closest proto-\/object in the robot\textquotesingle{}s visual field using stereo-\/vision.\hypertarget{md__home_runner_work_segmentation_segmentation_gh_pages_dispBlobber_README_autotoc_md0}{}\doxysection{Description}\label{md__home_runner_work_segmentation_segmentation_gh_pages_dispBlobber_README_autotoc_md0}
This module takes as input a disparity map (grayscale image) and provides as output the closest (brightest) blob, which is generally an object or proto-\/object in the scene. The output is provided in the following forms\+:


\begin{DoxyItemize}
\item binary image with the segmented blob
\item cropped rectangular region enclosing the segmented blob on the input disparity map
\item 2D top-\/left (TL) and bottom-\/right (BR) pixel coordinates of the cropped rectangular region on the input disparity map -\/eventually averaged over a frame buffer of arbitrary size-\/
\item 2D pixel coordinates of the centroid of the segmented blob -\/eventually averaged over the same frame buffer-\/ on the input disparity map
\end{DoxyItemize}

If the input disparity map comes from the \href{https://github.com/robotology/stereo-vision}{\texttt{ SFM}} module and this module is connected to the RPC port of the \href{https://github.com/robotology/stereo-vision}{\texttt{ SFM}}, then the stereo pairs (correspondent 2D points on the other camera) and the 3D re-\/projections in the world reference frame of the above points (blob\textquotesingle{}s TL and BR ROI vertices and centroid) are also provided as output.

The centroid\textquotesingle{}s coordinates of the closest blob in the scene provided by this module can be fed to the \href{http://wiki.icub.org/iCub_documentation/group__actionsRenderingEngine.html}{\texttt{ ARE}} or directly to the \href{http://wiki.icub.org/iCub_documentation/group__iKinGazeCtrl.html}{\texttt{ i\+Kin\+Gaze\+Ctrl}} module in order to focus the robot\textquotesingle{}s gaze on the object of interest. If the data connection is streamlined then the robot keeps on focusing on the closest proto-\/object in its visual field.

Example applications of the usage of this module can be found here\+:
\begin{DoxyItemize}
\item \href{https://github.com/robotology/onthefly-recognition}{\texttt{ onthefly-\/recognition}}\+: demo to teach the i\+Cub to recognize new objects on-\/the-\/fly.
\item \href{https://github.com/GiuliaP/icubworld}{\texttt{ icubworld}}\+: application to acquire a dataset of images from the i\+Cub\textquotesingle{}s cameras while the robot is observing a set of objects shown by a human operator. The dataset can be used, e.\+g., to train/benchmark offline a visual recognition system. 
\end{DoxyItemize}